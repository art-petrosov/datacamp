{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in Python (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1. Introduction and flat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `r`\tоткрытие на чтение (является значением по умолчанию)  \n",
    "* `w`\tоткрытие на запись, содержимое файла удаляется, если файла не существует, создается новый  \n",
    "* `x`\tоткрытие на запись, если файла не существует, иначе исключение  \n",
    "* `a`\tоткрытие на дозапись, информация добавляется в конец файла  \n",
    "* `b`\tоткрытие в двоичном режиме  \n",
    "* `t`\tоткрытие в текстовом режиме (является значением по умолчанию)  \n",
    "* `+`\tоткрытие на чтение и запись  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "filename = 'huck_finn.txt'\n",
    "file = open(filename, 'r')\n",
    "text = file.read()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with open(filename, 'r') as file:\n",
    "    print(file.read())\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Importing_Data_in_Python_Part1/moby_dick.txt', 'w') as file:\n",
    "    file.write('CHAPTER 1. Loomings.\\nCall me Ishmael. Some years ago--never mind how long \\\n",
    "               precisely--having\\n little or no money in my purse, and nothing particular to \\\n",
    "               interest me on\\n shore, I thought I would sail about a little and see the \\\n",
    "               watery part of\\n the world. It is a way I have of driving off the spleen and \\\n",
    "               regulating\\n the circulation. Whenever I find myself growing grim about the \\\n",
    "               mouth;\\n whenever it is a damp, drizzly November in my soul; whenever I \\\n",
    "               find\\n myself involuntarily pausing before coffin warehouses, and bringing \\\n",
    "               up\\n the rear of every funeral I meet; and especially whenever my hypos get\\n \\\n",
    "               such an upper hand of me, that it requires a strong moral principle to\\n \\\n",
    "               prevent me from deliberately stepping into the street, and methodically\\n \\\n",
    "               knocking people\\'s hats off--then, I account it high time to get to sea\\n as \\\n",
    "               soon as I can. This is my substitute for pistol and ball. With a\\n \\\n",
    "               philosophical flourish Cato throws himself upon his sword; I quietly\\n take \\\n",
    "               to the ship. There is nothing surprising in this. If they but knew\\n it, \\\n",
    "               almost all men in their degree, some time or other, cherish very\\n nearly the \\\n",
    "               same feelings towards the ocean with me.')\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "Call me Ishmael. Some years ago--never mind how long                precisely--having\n",
      " little or no money in my purse, and nothing particular to                interest me on\n",
      " shore, I thought I would sail about a little and see the                watery part of\n",
      " the world. It is a way I have of driving off the spleen and                regulating\n",
      " the circulation. Whenever I find myself growing grim about the                mouth;\n",
      " whenever it is a damp, drizzly November in my soul; whenever I                find\n",
      " myself involuntarily pausing before coffin warehouses, and bringing                up\n",
      " the rear of every funeral I meet; and especially whenever my hypos get\n",
      "                such an upper hand of me, that it requires a strong moral principle to\n",
      "                prevent me from deliberately stepping into the street, and methodically\n",
      "                knocking people's hats off--then, I account it high time to get to sea\n",
      " as                soon as I can. This is my substitute for pistol and ball. With a\n",
      "                philosophical flourish Cato throws himself upon his sword; I quietly\n",
      " take                to the ship. There is nothing surprising in this. If they but knew\n",
      " it,                almost all men in their degree, some time or other, cherish very\n",
      " nearly the                same feelings towards the ocean with me.\n"
     ]
    }
   ],
   "source": [
    "with open('Importing_Data_in_Python_Part1/moby_dick.txt', 'r') as file:\n",
    "    print(file.read())\n",
    "    file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing flat files using NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "file = 'digits_header.txt'\n",
    "\n",
    "# Skip the 1st row and choose 1st and 3rd columns\n",
    "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0,2])\n",
    "\n",
    "```\n",
    "\n",
    "* Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. \n",
    "\n",
    "```python\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "```\n",
    "\n",
    "```python\n",
    "np.recfromcsv('filename')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importing flat files using Pandas¶\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data_frame = pd.read_csv('filename.csv', nrows=10, header=None)\n",
    "\n",
    "data_array = data_frame.values\n",
    "\n",
    "```\n",
    "\n",
    "* Clean data from comments occurring in flat files, empty lines and missing values\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(file, sep='\\t', comment='#',\n",
    "                   na_values=['NA', 'NaN', 'Nothing'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2. Importing data from other file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introduction to other file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other filetypes:\n",
    "\n",
    "* Excel spreadsheets\n",
    "* MATLAB files\n",
    "* SAS files\n",
    "* STATA files\n",
    "* HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickled files\n",
    "\n",
    "* File type native to Python\n",
    "* Motivation: many datatypes for which it isn't obvious how to store them\n",
    "* Pickled files are serialized\n",
    "* Seriolize = convert object to byte stream\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "with open('pickled_fruit.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "{'apples': 14, 'bananas': 43, 'oranges': 6}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Excel spreadsheets\n",
    "\n",
    "```python\n",
    "file = 'urbanpop.xlsx'\n",
    "\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    "print(data.sheet_names)\n",
    "```\n",
    "```\n",
    "['1960-1969', '1970-1979', '1980-1989']\n",
    "```\n",
    "\n",
    "```\n",
    "df1 = data.parse('1960-1969') # import '1960-1969' sheet as df1 variable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bible os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a pickled file\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    d = pickle.load(file)\n",
    "\n",
    "print(type(d))\n",
    "\n",
    "```\n",
    "`<class 'dict'>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing your spreadsheet import\n",
    "\n",
    "```python\n",
    "df2 = xl.parse(xl.sheet_names[1], parse_cols=[0],\n",
    "               skiprows=1, names=['Country'])\n",
    "```\n",
    "\n",
    "* The additional arguments skiprows, names and `parse_cols`. These skip rows, name the columns and designate which columns to parse, respectively. All these arguments can be assigned to lists containing the specific row numbers, strings and column numbers, as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importing SAS/Stata files using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAS and Stata files\n",
    "\n",
    "* __SAS__ - Statistical Analysis System\n",
    "* __Stata__ - 'Statictics' + 'data'\n",
    "\n",
    "\n",
    "* __SAS__: business analytics and biostatistics\n",
    "* __Stata__: academic social sciences research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAS files\n",
    "\n",
    "* Used for:\n",
    "  * Advanced analytics\n",
    "  * Multivariate analysis\n",
    "  * Business intelligence\n",
    "  * Data management\n",
    "  * Predictive analytics\n",
    "* Standard for computational analysis\n",
    "* `.sas7bdat` or `.sas7bcat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing SAS files\n",
    "\n",
    "* __SAS__ - Statistical Analysis System\n",
    "* __Stata__ - 'Statictics' + 'data'\n",
    "\n",
    "\n",
    "* __SAS__: business analytics and biostatistics\n",
    "* __Stata__: academic social sciences research\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('urbanpop.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Stata files\n",
    "\n",
    "```python\n",
    "data = pd.read_stata('file_name.dta')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Importing HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 files\n",
    "\n",
    "* Hierarchical Data Format version 5\n",
    "* Standard for storing large quantities of numerical data\n",
    "* Datasets can be hundreds of gigabytes or terabytes\n",
    "* HDF5 can scale to exabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing HDF5 files\n",
    "\n",
    "```python\n",
    "In [1]: import h5py\n",
    "    \n",
    "In [2]: filename = 'H-H1_LOSC_4_V1-815411200-4096.hdf5'\n",
    "    \n",
    "In [3]: data = h5py.File(filename, 'r') # 'r' is to read\n",
    "    \n",
    "In [4]: print(type(data))\n",
    "        <class 'h5py._hl.files.File'>\n",
    "        \n",
    "In [5]: for key in data.keys():\n",
    "            print(key)\n",
    "Out[5]: meta\n",
    "        quality\n",
    "        strain\n",
    "        \n",
    "In [6]: print(type(data['meta']))\n",
    "        <class 'h5py._hl.group.Group'>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The structure of HDF5 files\n",
    "\n",
    "```python\n",
    "In [7]: for key in data['meta'].keys():\n",
    "            print(key)\n",
    "        \n",
    "Out[7]: Description\n",
    "        DescriptionURL\n",
    "        Detector\n",
    "        Duration\n",
    "        GPSstart\n",
    "        Observatory\n",
    "        Type\n",
    "        UTCstart\n",
    "        \n",
    "In [8]: print(data['meta']['Description'].value,\n",
    "              data['meta']['Detector'].value)\n",
    "    \n",
    "        b'Strain data time series from LIGO' b'H1'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The HDF Project\n",
    "\n",
    "* Actively maintained by the HDF Group\n",
    "* Based in Champaign, Illinois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importing MATLAB files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB\n",
    "\n",
    "* 'Matrix Laboratory'\n",
    "* Industry standard in engineering and science\n",
    "* Data saved as .mat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy to the rescue!\n",
    "\n",
    "* `scipy.io.loadmat()` - read .mat files\n",
    "* `scipy.io.savemat()` - write .mat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a .mat file\n",
    "\n",
    "```python\n",
    "In [1]: import scipy.io\n",
    "    \n",
    "In [2]: filename = 'workspace.mat'\n",
    "    \n",
    "In [3]: mat = scipy.io.loadmat(filename)\n",
    "    \n",
    "In [4]: print(type(mat))\n",
    "    \n",
    "        <class 'dict'>\n",
    "    \n",
    "In [5]: print(type(mat['x']))\n",
    "    \n",
    "        <class 'numpy.ndarray'>\n",
    "```\n",
    "\n",
    "* keys = MATLAB variable names\n",
    "* values = objects assigned to variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3. Working with relational databases in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Introduction to relational databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a relational database?\n",
    "\n",
    "* Based on relational model of data\n",
    "* First described by Edgar 'Ted' Codd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational model\n",
    "\n",
    "* Widely adopted\n",
    "* Todd’s 12 Rules/Commandments\n",
    "* Consists of 13 rules (zero-indexed!)\n",
    "* Describes what a Relational Database Management System should adhere to to be considered relational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Database Management Systems\n",
    "\n",
    "* PostgreSQL\n",
    "* MySQL\n",
    "* SQLite\n",
    "* SQL = Structured Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Database\n",
    "\n",
    "* Each row or record in a table represents an instance of an entity type\n",
    "* Each column in a table represents an attribute or feature of an instance\n",
    "* Every table contains a primary key column, which has a unique entry for each row\n",
    "* There are relations between tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Creating a database engine in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a database engine\n",
    "\n",
    "* SQLite database\n",
    "  * Fast and simple\n",
    "* SQLAlchemy\n",
    "  * Works with many Relational Database Management Systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category', 'Customer', 'CustomerCustomerDemo', 'CustomerDemographic', 'Employee', 'EmployeeTerritory', 'Order', 'OrderDetail', 'Product', 'Region', 'Shipper', 'Supplier', 'Territory']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')\n",
    "\n",
    "table_names = engine.table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Querying relational databases in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic SQL query\n",
    "\n",
    "`SELECT * FROM Table_Name`\n",
    "\n",
    "* Returns all columns of all rows of the table\n",
    "* Example:\n",
    "\n",
    "`SELECT * FROM Orders`\n",
    "\n",
    "* We’ll use SQLAlchemy and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow of SQL querying\n",
    "\n",
    "* Import packages and functions\n",
    "* Create the database engine\n",
    "* Connect to the engine\n",
    "* Query the database\n",
    "* Save query results to a DataFrame\n",
    "* Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')\n",
    "\n",
    "con = engine.connect()\n",
    "rs = con.execute('SELECT * FROM Employee')\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing your query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0          1         2                      3     4           5   \\\n",
      "0   1    Davolio     Nancy   Sales Representative   Ms.  1980-12-08   \n",
      "1   2     Fuller    Andrew  Vice President, Sales   Dr.  1984-02-19   \n",
      "2   3  Leverling     Janet   Sales Representative   Ms.  1995-08-30   \n",
      "3   4    Peacock  Margaret   Sales Representative  Mrs.  1969-09-19   \n",
      "4   5   Buchanan    Steven          Sales Manager   Mr.  1987-03-04   \n",
      "\n",
      "           6                           7         8              9        10  \\\n",
      "0  2024-05-01  507 - 20th Ave. E. Apt. 2A   Seattle  North America    98122   \n",
      "1  2024-08-14          908 W. Capital Way    Tacoma  North America    98401   \n",
      "2  2024-04-01          722 Moss Bay Blvd.  Kirkland  North America    98033   \n",
      "3  2025-05-03        4110 Old Redmond Rd.   Redmond  North America    98052   \n",
      "4  2025-10-17             14 Garrett Hill    London  British Isles  SW1 8JR   \n",
      "\n",
      "    11              12    13    14  \\\n",
      "0  USA  (206) 555-9857  5467  None   \n",
      "1  USA  (206) 555-9482  3457  None   \n",
      "2  USA  (206) 555-3412  3355  None   \n",
      "3  USA  (206) 555-8122  5176  None   \n",
      "4   UK   (71) 555-4848  3453  None   \n",
      "\n",
      "                                                  15   16  \\\n",
      "0  Education includes a BA in psychology from Col...  2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...  NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...  2.0   \n",
      "3  Margaret holds a BA in English literature from...  2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...  2.0   \n",
      "\n",
      "                                       17  \n",
      "0    http://accweb/emmployees/davolio.bmp  \n",
      "1     http://accweb/emmployees/fuller.bmp  \n",
      "2  http://accweb/emmployees/leverling.bmp  \n",
      "3    http://accweb/emmployees/peacock.bmp  \n",
      "4   http://accweb/emmployees/buchanan.bmp  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the DataFrame column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   LastName FirstName                  Title TitleOfCourtesy   BirthDate  \\\n",
      "0   1    Davolio     Nancy   Sales Representative             Ms.  1980-12-08   \n",
      "1   2     Fuller    Andrew  Vice President, Sales             Dr.  1984-02-19   \n",
      "2   3  Leverling     Janet   Sales Representative             Ms.  1995-08-30   \n",
      "3   4    Peacock  Margaret   Sales Representative            Mrs.  1969-09-19   \n",
      "4   5   Buchanan    Steven          Sales Manager             Mr.  1987-03-04   \n",
      "\n",
      "     HireDate                     Address      City         Region PostalCode  \\\n",
      "0  2024-05-01  507 - 20th Ave. E. Apt. 2A   Seattle  North America      98122   \n",
      "1  2024-08-14          908 W. Capital Way    Tacoma  North America      98401   \n",
      "2  2024-04-01          722 Moss Bay Blvd.  Kirkland  North America      98033   \n",
      "3  2025-05-03        4110 Old Redmond Rd.   Redmond  North America      98052   \n",
      "4  2025-10-17             14 Garrett Hill    London  British Isles    SW1 8JR   \n",
      "\n",
      "  Country       HomePhone Extension Photo  \\\n",
      "0     USA  (206) 555-9857      5467  None   \n",
      "1     USA  (206) 555-9482      3457  None   \n",
      "2     USA  (206) 555-3412      3355  None   \n",
      "3     USA  (206) 555-8122      5176  None   \n",
      "4      UK   (71) 555-4848      3453  None   \n",
      "\n",
      "                                               Notes  ReportsTo  \\\n",
      "0  Education includes a BA in psychology from Col...        2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...        NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...        2.0   \n",
      "3  Margaret holds a BA in English literature from...        2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...        2.0   \n",
      "\n",
      "                                PhotoPath  \n",
      "0    http://accweb/emmployees/davolio.bmp  \n",
      "1     http://accweb/emmployees/fuller.bmp  \n",
      "2  http://accweb/emmployees/leverling.bmp  \n",
      "3    http://accweb/emmployees/peacock.bmp  \n",
      "4   http://accweb/emmployees/buchanan.bmp  \n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')\n",
    "\n",
    "con = engine.connect()\n",
    "rs = con.execute('SELECT * FROM Employee')\n",
    "\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "df.columns = rs.keys()\n",
    "con.close() \n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the context manager\n",
    "\n",
    "* Method `.fetchall()` imports all rows\n",
    "* Mothod `.fetchmany(size=n)` imports `n` rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT Id, FirstName, LastName FROM Employee')\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering quirying\n",
    "\n",
    "```SQL\n",
    "SELECT * FROM Customer WHERE Country = 'Canada'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering your SQL records \n",
    "\n",
    "```SQL\n",
    "SELECT * FROM Customer ORDER BY SupportRepId\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM Employee', engine)\n",
    "df = pd.read_sql_query('SELECT * FROM Employee WHERE Id >= 6 ORDER BY BirthDate', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced querying: exploiting table relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INNER JOIN in Python (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FirstName LastName TerritoryId\n",
      "0     Nancy  Davolio       06897\n",
      "1     Nancy  Davolio       19713\n",
      "2    Andrew   Fuller       01581\n",
      "3    Andrew   Fuller       01730\n",
      "4    Andrew   Fuller       01833\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Importing_Data_in_Python_Part1/Northwind.sqlite')\n",
    "\n",
    "df = pd.read_sql_query('SELECT FirstName, LastName, TerritoryId FROM Employee \\\n",
    "                        INNER JOIN EmployeeTerritory \\\n",
    "                        on Employee.Id = EmployeeTerritory.EmployeeID', engine)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of joining columns 'FirstName' and 'SecondName' of tables 'Employee' and 'EmployeeTerritory' by the column 'TerritoryId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FirstName LastName TerritoryId\n",
      "0     Nancy  Davolio       06897\n",
      "1     Nancy  Davolio       19713\n",
      "2    Andrew   Fuller       01581\n",
      "3    Andrew   Fuller       01730\n",
      "4    Andrew   Fuller       01833\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT FirstName, LastName, TerritoryId FROM Employee \\\n",
    "                      INNER JOIN EmployeeTerritory \\\n",
    "                      on Employee.Id = EmployeeTerritory.EmployeeID')\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
